# The Exchange Room
In this project we are analysing the stock market data throgh azure cloud services. Here we are performing operations on databricks workspace on azure.After analysing the data we are implementing the power Bi for visualization of data. finally In this project we are connected azure devops services from azure platform for implementing CI/CD pipelines for implementing and deployement purpose.

## Requirements
1. Functionality should reflect the below user stories.
2. performing this project we need azure platform with access.
3. Databricks workspacs need to be launch.
4. set up all datbricks and sql services for performing operations through notebook.
5. Data is imported in a CSV File formate to azure datafactory.
6. Data Access is performed through the use of Csv file using file path with Sparkseassion.
7. Data functions  is done using Sparksession and RDDs in spark Framework.
8. Driver code and functionalities is done using python.

## STEPS TO RUN PROJECT
1. Log in into  microsoft azure or azure databricks account. 
2. Create sparkSession using spark and load and read the csv file .
3. Copy the code from code.txt from code folder and paste into the databricks platform.
4. Press shift+ enter or run in databricks platform to run the code.

## TOOLS AND TECHNOLOGIES

1. SPARK
2. PYTHON
3. PYSPARK 
4. SPARK SQL 
5. MICROSOFT AZURE 
6. AZURE DEVOPS SERVICES
7. DATABRICKS
8. DATAFRAMES
9. Power BI

## ROLES AND RESPONSIBILITY
1. WORKED WITH AZURE DEVOPS SERVICES FOR CONTINIOUS INTEGRATION AND CONTINIOUS DELIVERY.
2. WROTE YML SCRIPT FOR AUTOMATING  CONTINIOUS DELIVERY.
3. CREATED VIRTUAL MACHINES AND STORAGE ACCOUNT IN AZURE PLATFORM.
4. WORKED WITH AZURE DATABRICKS AND ITS VARIOUS COMPUTING SERVICES.
5. CREATED RESUABLE METHODS FOR GETTING INSIGHTS FROM THE DATASETS USING PYTHON.
6. CREATED VISUVALS LIKE GRAPHS, CHARTS, AND FLOW DIAGRAMS USING POWER BI.

### CONTRIBUTORS
* Ravalika.U
